{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NNI_usage_example",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "REF: https://towardsdatascience.com/how-to-improve-any-ml-dl-performance-by-10-easily-90dbbd01a4b3 "
      ],
      "metadata": {
        "id": "VjSYBBCadQ9B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BriRH51PCAxH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3934037f-93ae-4d7e-eaff-b48276079f96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nni\n",
            "  Downloading nni-2.7-py3-none-manylinux1_x86_64.whl (56.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 56.1 MB 1.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from nni) (21.3)\n",
            "Requirement already satisfied: hyperopt==0.1.2 in /usr/local/lib/python3.7/dist-packages (from nni) (0.1.2)\n",
            "Collecting PythonWebHDFS\n",
            "  Downloading PythonWebHDFS-0.2.3-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from nni) (2.23.0)\n",
            "Collecting json-tricks>=3.15.5\n",
            "  Downloading json_tricks-3.15.5-py2.py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: numpy<1.22 in /usr/local/lib/python3.7/dist-packages (from nni) (1.21.6)\n",
            "Collecting schema\n",
            "  Downloading schema-0.7.5-py2.py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from nni) (3.6.0)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from nni) (1.3.0)\n",
            "Collecting responses\n",
            "  Downloading responses-0.20.0-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from nni) (1.3.5)\n",
            "Collecting websockets>=10.1\n",
            "  Downloading websockets-10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 35.3 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.4\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 53.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from nni) (4.2.0)\n",
            "Requirement already satisfied: prettytable in /usr/local/lib/python3.7/dist-packages (from nni) (3.2.0)\n",
            "Requirement already satisfied: scikit-learn>=0.24.1 in /usr/local/lib/python3.7/dist-packages (from nni) (1.0.2)\n",
            "Requirement already satisfied: typeguard in /usr/local/lib/python3.7/dist-packages (from nni) (2.7.1)\n",
            "Requirement already satisfied: astor in /usr/local/lib/python3.7/dist-packages (from nni) (0.8.1)\n",
            "Requirement already satisfied: scipy<1.8 in /usr/local/lib/python3.7/dist-packages (from nni) (1.4.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from nni) (5.4.8)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from hyperopt==0.1.2->nni) (0.16.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from hyperopt==0.1.2->nni) (2.6.3)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.7/dist-packages (from hyperopt==0.1.2->nni) (4.1.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from hyperopt==0.1.2->nni) (4.64.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from hyperopt==0.1.2->nni) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24.1->nni) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24.1->nni) (1.1.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->nni) (3.0.8)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->nni) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->nni) (2.8.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from prettytable->nni) (4.11.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prettytable->nni) (0.2.5)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->prettytable->nni) (3.8.0)\n",
            "Collecting simplejson\n",
            "  Downloading simplejson-3.17.6-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (130 kB)\n",
            "\u001b[K     |████████████████████████████████| 130 kB 40.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->nni) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->nni) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->nni) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->nni) (2021.10.8)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 10.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: contextlib2>=0.5.5 in /usr/local/lib/python3.7/dist-packages (from schema->nni) (0.5.5)\n",
            "Installing collected packages: urllib3, simplejson, websockets, schema, responses, pyyaml, PythonWebHDFS, json-tricks, colorama, nni\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed PythonWebHDFS-0.2.3 colorama-0.4.4 json-tricks-3.15.5 nni-2.7 pyyaml-6.0 responses-0.20.0 schema-0.7.5 simplejson-3.17.6 urllib3-1.25.11 websockets-10.3\n"
          ]
        }
      ],
      "source": [
        "#install packages\n",
        "!pip install nni "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MNIST Classification **without NNI**"
      ],
      "metadata": {
        "id": "ehKdTB2abmbq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch \n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "import nni"
      ],
      "metadata": {
        "id": "eqtPZyiLE-Wd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "804dde87-4d6a-46c4-b345-0a689051a276"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2022-04-29 05:47:28] INFO (numexpr.utils/MainThread) NumExpr defaulting to 2 threads.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, device, train_loader, loss_fn, optimiser):\n",
        "  size = len(train_loader.dataset)\n",
        "  model.train()\n",
        "  \n",
        "  for batch, (X,y) in enumerate(train_loader):\n",
        "    X, y = X.to(device), y.to(device)\n",
        "\n",
        "    #compute prediction error \n",
        "    pred = model(X)\n",
        "    loss = loss_fn(pred,  y)\n",
        "\n",
        "    #backpropagation \n",
        "    optimiser.zero_grad()\n",
        "    loss.backward()\n",
        "    optimiser.step()\n",
        "\n",
        "    if batch %100 == 0:\n",
        "        loss, current = loss.item(), batch * len(X)\n",
        "        print (f\"loss: {loss:>7f} [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "def test(model, device, loss_fn, test_loader):\n",
        "  size = len(test_loader.dataset)\n",
        "  num_batches = len(test_loader)\n",
        "  model.eval()\n",
        "  test_loss, correct = 0,0\n",
        "  with torch.no_grad():\n",
        "    for X, y in test_loader:\n",
        "      X, y = X.to(device), y.to(device)\n",
        "      pred = model(X)\n",
        "      test_loss += loss_fn(pred, y).item()\n",
        "      correct += (pred.argmax(1)==y).type(torch.float).sum().item()\n",
        "  test_loss/=num_batches\n",
        "  correct /= size \n",
        "  print(f\"Test Error: \\n Accuracy {(100*correct):>0.1f}%, Avg Loss: {test_loss:>8f} \\n\")\n",
        "  return correct"
      ],
      "metadata": {
        "id": "LG3YYmIlb_0l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main(args):\n",
        "  training_data = datasets.FashionMNIST(root=\"data\", train=True, download=True,transform=ToTensor(),)\n",
        "  testing_data = datasets.FashionMNIST(root=\"data\", train=False, download=True,transform=ToTensor(),)\n",
        "\n",
        "  train_dataloader = DataLoader(training_data,batch_size=args['batch_size'])\n",
        "  test_dataloader = DataLoader(testing_data,batch_size = 64)\n",
        "\n",
        "  device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "  print(f\"Using {device} device\")\n",
        "\n",
        "  #Define Model \n",
        "  class NeuralNetwork(nn.Module):\n",
        "    def __init__(self, hidden_size1, hidden_size2 ):\n",
        "      super(NeuralNetwork,self).__init__()\n",
        "      self.flatten = nn.Flatten()\n",
        "      self.linear_relu_stack = nn.Sequential(\n",
        "          nn.Linear(28*28, hidden_size1),\n",
        "          nn.ReLU(), \n",
        "          nn.Linear(hidden_size1, hidden_size2),\n",
        "          nn.ReLU(),\n",
        "          nn.Linear(hidden_size2,10)\n",
        "      )\n",
        "    def forward(self, x):\n",
        "      x = self.flatten(x)\n",
        "      logits = self.linear_relu_stack(x)\n",
        "      return logits\n",
        "  \n",
        "  model = NeuralNetwork(hidden_size1=args['hidden_size1'],\n",
        "                        hidden_size2=args['hidden_size2']).to(device)\n",
        "  print(model)\n",
        "  loss_fn = nn.CrossEntropyLoss()\n",
        "  optimiser = torch.optim.SGD(model.parameters(), lr=args['lr'])\n",
        "\n",
        "  for epoch in range(10):\n",
        "    print(f'Epoch {epoch+1}\\n ------------------------')\n",
        "    train(model, device, train_dataloader, loss_fn, optimiser)\n",
        "    test_acc = test(model, device, loss_fn, test_dataloader)\n",
        "    print(test_acc)\n",
        "  print(f'final accuracy:{test_acc}')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  params = {\n",
        "      'batch_size':32,\n",
        "      'hidden_size1':128,\n",
        "      'hidden_size2':128,\n",
        "      'lr':0.001,\n",
        "      'momentum':0.5\n",
        "  }\n",
        "  main(params)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "it_wWObD2126",
        "outputId": "f6313207-d64f-4562-e382-b9fb4f10786c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=128, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Epoch 1\n",
            " ------------------------\n",
            "loss: 2.305076 [    0/60000]\n",
            "loss: 2.299222 [ 3200/60000]\n",
            "loss: 2.288804 [ 6400/60000]\n",
            "loss: 2.280372 [ 9600/60000]\n",
            "loss: 2.272156 [12800/60000]\n",
            "loss: 2.264546 [16000/60000]\n",
            "loss: 2.247690 [19200/60000]\n",
            "loss: 2.249331 [22400/60000]\n",
            "loss: 2.256461 [25600/60000]\n",
            "loss: 2.209541 [28800/60000]\n",
            "loss: 2.203690 [32000/60000]\n",
            "loss: 2.188910 [35200/60000]\n",
            "loss: 2.211001 [38400/60000]\n",
            "loss: 2.166477 [41600/60000]\n",
            "loss: 2.138067 [44800/60000]\n",
            "loss: 2.115976 [48000/60000]\n",
            "loss: 2.129153 [51200/60000]\n",
            "loss: 2.091841 [54400/60000]\n",
            "loss: 2.033167 [57600/60000]\n",
            "Test Error: \n",
            " Accuracy 54.7%, Avg Loss: 2.034706 \n",
            "\n",
            "0.5473\n",
            "Epoch 2\n",
            " ------------------------\n",
            "loss: 2.030101 [    0/60000]\n",
            "loss: 2.011865 [ 3200/60000]\n",
            "loss: 1.975574 [ 6400/60000]\n",
            "loss: 1.942268 [ 9600/60000]\n",
            "loss: 1.891583 [12800/60000]\n",
            "loss: 1.917986 [16000/60000]\n",
            "loss: 1.812606 [19200/60000]\n",
            "loss: 1.777767 [22400/60000]\n",
            "loss: 1.778911 [25600/60000]\n",
            "loss: 1.706195 [28800/60000]\n",
            "loss: 1.566285 [32000/60000]\n",
            "loss: 1.531269 [35200/60000]\n",
            "loss: 1.708312 [38400/60000]\n",
            "loss: 1.562203 [41600/60000]\n",
            "loss: 1.468901 [44800/60000]\n",
            "loss: 1.429623 [48000/60000]\n",
            "loss: 1.523902 [51200/60000]\n",
            "loss: 1.505334 [54400/60000]\n",
            "loss: 1.354594 [57600/60000]\n",
            "Test Error: \n",
            " Accuracy 59.3%, Avg Loss: 1.387109 \n",
            "\n",
            "0.5928\n",
            "Epoch 3\n",
            " ------------------------\n",
            "loss: 1.387866 [    0/60000]\n",
            "loss: 1.388992 [ 3200/60000]\n",
            "loss: 1.356258 [ 6400/60000]\n",
            "loss: 1.402781 [ 9600/60000]\n",
            "loss: 1.279979 [12800/60000]\n",
            "loss: 1.416779 [16000/60000]\n",
            "loss: 1.176660 [19200/60000]\n",
            "loss: 1.186827 [22400/60000]\n",
            "loss: 1.267815 [25600/60000]\n",
            "loss: 1.260126 [28800/60000]\n",
            "loss: 1.114402 [32000/60000]\n",
            "loss: 1.060803 [35200/60000]\n",
            "loss: 1.367866 [38400/60000]\n",
            "loss: 1.176477 [41600/60000]\n",
            "loss: 1.112300 [44800/60000]\n",
            "loss: 1.024599 [48000/60000]\n",
            "loss: 1.150867 [51200/60000]\n",
            "loss: 1.237852 [54400/60000]\n",
            "loss: 1.019537 [57600/60000]\n",
            "Test Error: \n",
            " Accuracy 63.4%, Avg Loss: 1.076999 \n",
            "\n",
            "0.6339\n",
            "Epoch 4\n",
            " ------------------------\n",
            "loss: 1.062824 [    0/60000]\n",
            "loss: 1.075228 [ 3200/60000]\n",
            "loss: 1.072743 [ 6400/60000]\n",
            "loss: 1.218721 [ 9600/60000]\n",
            "loss: 0.997808 [12800/60000]\n",
            "loss: 1.181937 [16000/60000]\n",
            "loss: 0.896461 [19200/60000]\n",
            "loss: 0.898070 [22400/60000]\n",
            "loss: 0.998808 [25600/60000]\n",
            "loss: 1.126046 [28800/60000]\n",
            "loss: 0.912326 [32000/60000]\n",
            "loss: 0.844611 [35200/60000]\n",
            "loss: 1.217572 [38400/60000]\n",
            "loss: 1.017775 [41600/60000]\n",
            "loss: 0.952582 [44800/60000]\n",
            "loss: 0.821735 [48000/60000]\n",
            "loss: 0.958541 [51200/60000]\n",
            "loss: 1.107649 [54400/60000]\n",
            "loss: 0.857870 [57600/60000]\n",
            "Test Error: \n",
            " Accuracy 66.0%, Avg Loss: 0.920079 \n",
            "\n",
            "0.6603\n",
            "Epoch 5\n",
            " ------------------------\n",
            "loss: 0.882030 [    0/60000]\n",
            "loss: 0.923588 [ 3200/60000]\n",
            "loss: 0.922571 [ 6400/60000]\n",
            "loss: 1.093843 [ 9600/60000]\n",
            "loss: 0.842943 [12800/60000]\n",
            "loss: 1.048489 [16000/60000]\n",
            "loss: 0.739855 [19200/60000]\n",
            "loss: 0.730898 [22400/60000]\n",
            "loss: 0.844508 [25600/60000]\n",
            "loss: 1.066326 [28800/60000]\n",
            "loss: 0.792252 [32000/60000]\n",
            "loss: 0.727394 [35200/60000]\n",
            "loss: 1.125358 [38400/60000]\n",
            "loss: 0.941508 [41600/60000]\n",
            "loss: 0.880493 [44800/60000]\n",
            "loss: 0.713990 [48000/60000]\n",
            "loss: 0.850520 [51200/60000]\n",
            "loss: 1.027162 [54400/60000]\n",
            "loss: 0.773782 [57600/60000]\n",
            "Test Error: \n",
            " Accuracy 68.7%, Avg Loss: 0.832092 \n",
            "\n",
            "0.6873\n",
            "Epoch 6\n",
            " ------------------------\n",
            "loss: 0.770750 [    0/60000]\n",
            "loss: 0.850718 [ 3200/60000]\n",
            "loss: 0.824131 [ 6400/60000]\n",
            "loss: 0.989556 [ 9600/60000]\n",
            "loss: 0.752372 [12800/60000]\n",
            "loss: 0.976285 [16000/60000]\n",
            "loss: 0.652684 [19200/60000]\n",
            "loss: 0.628288 [22400/60000]\n",
            "loss: 0.754341 [25600/60000]\n",
            "loss: 1.027698 [28800/60000]\n",
            "loss: 0.723863 [32000/60000]\n",
            "loss: 0.662750 [35200/60000]\n",
            "loss: 1.061054 [38400/60000]\n",
            "loss: 0.906884 [41600/60000]\n",
            "loss: 0.845825 [44800/60000]\n",
            "loss: 0.652263 [48000/60000]\n",
            "loss: 0.783964 [51200/60000]\n",
            "loss: 0.969714 [54400/60000]\n",
            "loss: 0.726517 [57600/60000]\n",
            "Test Error: \n",
            " Accuracy 70.8%, Avg Loss: 0.776775 \n",
            "\n",
            "0.7076\n",
            "Epoch 7\n",
            " ------------------------\n",
            "loss: 0.696530 [    0/60000]\n",
            "loss: 0.812972 [ 3200/60000]\n",
            "loss: 0.751052 [ 6400/60000]\n",
            "loss: 0.901380 [ 9600/60000]\n",
            "loss: 0.690550 [12800/60000]\n",
            "loss: 0.934310 [16000/60000]\n",
            "loss: 0.600960 [19200/60000]\n",
            "loss: 0.558671 [22400/60000]\n",
            "loss: 0.694449 [25600/60000]\n",
            "loss: 0.996220 [28800/60000]\n",
            "loss: 0.685653 [32000/60000]\n",
            "loss: 0.621485 [35200/60000]\n",
            "loss: 1.006148 [38400/60000]\n",
            "loss: 0.889086 [41600/60000]\n",
            "loss: 0.821973 [44800/60000]\n",
            "loss: 0.611676 [48000/60000]\n",
            "loss: 0.734628 [51200/60000]\n",
            "loss: 0.923795 [54400/60000]\n",
            "loss: 0.695876 [57600/60000]\n",
            "Test Error: \n",
            " Accuracy 72.7%, Avg Loss: 0.736406 \n",
            "\n",
            "0.7267\n",
            "Epoch 8\n",
            " ------------------------\n",
            "loss: 0.641733 [    0/60000]\n",
            "loss: 0.787152 [ 3200/60000]\n",
            "loss: 0.692231 [ 6400/60000]\n",
            "loss: 0.829343 [ 9600/60000]\n",
            "loss: 0.644139 [12800/60000]\n",
            "loss: 0.904489 [16000/60000]\n",
            "loss: 0.566570 [19200/60000]\n",
            "loss: 0.505218 [22400/60000]\n",
            "loss: 0.651011 [25600/60000]\n",
            "loss: 0.967914 [28800/60000]\n",
            "loss: 0.663740 [32000/60000]\n",
            "loss: 0.591594 [35200/60000]\n",
            "loss: 0.955267 [38400/60000]\n",
            "loss: 0.877055 [41600/60000]\n",
            "loss: 0.800874 [44800/60000]\n",
            "loss: 0.581060 [48000/60000]\n",
            "loss: 0.694187 [51200/60000]\n",
            "loss: 0.884851 [54400/60000]\n",
            "loss: 0.673743 [57600/60000]\n",
            "Test Error: \n",
            " Accuracy 74.3%, Avg Loss: 0.703788 \n",
            "\n",
            "0.7428\n",
            "Epoch 9\n",
            " ------------------------\n",
            "loss: 0.598978 [    0/60000]\n",
            "loss: 0.765413 [ 3200/60000]\n",
            "loss: 0.643700 [ 6400/60000]\n",
            "loss: 0.770800 [ 9600/60000]\n",
            "loss: 0.606357 [12800/60000]\n",
            "loss: 0.879561 [16000/60000]\n",
            "loss: 0.540692 [19200/60000]\n",
            "loss: 0.459897 [22400/60000]\n",
            "loss: 0.618403 [25600/60000]\n",
            "loss: 0.941164 [28800/60000]\n",
            "loss: 0.650327 [32000/60000]\n",
            "loss: 0.567764 [35200/60000]\n",
            "loss: 0.907733 [38400/60000]\n",
            "loss: 0.867411 [41600/60000]\n",
            "loss: 0.781182 [44800/60000]\n",
            "loss: 0.556416 [48000/60000]\n",
            "loss: 0.660493 [51200/60000]\n",
            "loss: 0.850856 [54400/60000]\n",
            "loss: 0.656380 [57600/60000]\n",
            "Test Error: \n",
            " Accuracy 75.6%, Avg Loss: 0.676118 \n",
            "\n",
            "0.756\n",
            "Epoch 10\n",
            " ------------------------\n",
            "loss: 0.565356 [    0/60000]\n",
            "loss: 0.745450 [ 3200/60000]\n",
            "loss: 0.602991 [ 6400/60000]\n",
            "loss: 0.723052 [ 9600/60000]\n",
            "loss: 0.574668 [12800/60000]\n",
            "loss: 0.857444 [16000/60000]\n",
            "loss: 0.520219 [19200/60000]\n",
            "loss: 0.420436 [22400/60000]\n",
            "loss: 0.593204 [25600/60000]\n",
            "loss: 0.914864 [28800/60000]\n",
            "loss: 0.641494 [32000/60000]\n",
            "loss: 0.547656 [35200/60000]\n",
            "loss: 0.863334 [38400/60000]\n",
            "loss: 0.859104 [41600/60000]\n",
            "loss: 0.764178 [44800/60000]\n",
            "loss: 0.536294 [48000/60000]\n",
            "loss: 0.633041 [51200/60000]\n",
            "loss: 0.820586 [54400/60000]\n",
            "loss: 0.641760 [57600/60000]\n",
            "Test Error: \n",
            " Accuracy 76.6%, Avg Loss: 0.652372 \n",
            "\n",
            "0.7656\n",
            "final accuracy:0.7656\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparam Search with NNI"
      ],
      "metadata": {
        "id": "F6ZLfwI78pKZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## STEP1. search.py"
      ],
      "metadata": {
        "id": "P8RxY31P8tz-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nni.experiment import Experiment\n",
        "from pathlib import Path\n",
        "import os, sys\n",
        "import time"
      ],
      "metadata": {
        "id": "TwZAIxBI8w8e"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#%% add parent_dir\n",
        "# parent_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\n",
        "# sys.path.append(parent_dir)"
      ],
      "metadata": {
        "id": "vHdmwHDs3U7B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = {\n",
        "    'batch_size':32,\n",
        "    'hidden_size1':128,\n",
        "    'hidden_size2':128,\n",
        "    'lr':0.001,\n",
        "    'momentum':0.5\n",
        "}"
      ],
      "metadata": {
        "id": "mYtt0ywD3yCP"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search_space = {\n",
        "    'batch_size':{'_type':'choice', '_value':[32, 64, 128, 256]},\n",
        "    'hidden_size1':{'_type':'choice', '_value':[64, 128, 256, 512]},\n",
        "    'hidden_size2':{'_type':'choice', '_value':[64, 128, 256, 512]},\n",
        "    'lr':{'_type':'loguniform', '_value':[0.0001, 0.1]},\n",
        "    'momentum':{'_type':'uniform','_value':[0 , 1]}\n",
        "}"
      ],
      "metadata": {
        "id": "bqwtPaFP3zom"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "experiment = Experiment('local')\n",
        "experiment.config.trial_code_directory = '.'\n",
        "experiment.config.trial_command = 'python mnist_nni.py' # command to run the code \n",
        "experiment.config.search_space = search_space\n",
        "experiment.config.tuner.name = 'TPE'\n",
        "experiment.config.tuner.class_args['optimize_mode'] = 'maximize'\n",
        "experiment.config.max_trial_number = 30                 # number of experiments to run. In general, TPE requires min 20 trials to warm up.\n",
        "experiment.config.trial_gpu_number = 0                  # CUDA is required when it’s greater than zero.\n",
        "experiment.config.trial_concurrency = 2\n",
        "experiment.run(8082)\n",
        "\n",
        "input ('Press Enter to Quit')\n",
        "experiment.stop()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SBZckyCa5asP",
        "outputId": "8329cbf4-00a6-40a1-f900-809bda104db1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2022-04-29 07:00:16] Creating experiment, Experiment ID: 2vyfw3mp\n",
            "[2022-04-29 07:00:16] Starting web server...\n",
            "[2022-04-29 07:00:17] Setting up...\n",
            "[2022-04-29 07:00:17] Web portal URLs: http://127.0.0.1:8082 http://172.28.0.2:8082\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "k44lk-Hy-MNj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "MJZ1J5fM7MAC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}